@article{alemi2012feasibility,
author = {Alemi, Farrokh and Torii, Manabu and Clementz, Laura and Aron, David C},
file = {::},
journal = {Quality Management in Healthcare},
number = {1},
pages = {9--19},
publisher = {LWW},
title = {{Feasibility of real-time satisfaction surveys through automated analysis of patients' unstructured comments and sentiments}},
volume = {21},
year = {2012}
}
@article{AlexaMcCray1993,
abstract = {This paper describes efforts to provide access to the free text in biomedical databases. The focus of the effort is the development of SPECIALIST, an experimental natural language processing system for the biomedical domain. The system includes a broad coverage parser supported by a large lexicon, modules that provide access to the extensive Unified Medical Language SystemG (UMLS{\textregistered}) Knowledge Sources, and a retrieval module that permits experiments in information retrieval. The UMLS Metathesaurus{\textregistered} and Semantic Network provide a rich source of biomedical concepts and their interrelationships. Investigations have been conducted to determine the type of information required to effect a map between the language of queries and the language of relevant documents. Mappings are never straightforward and often involve multiple inferences.},
author = {{Alexa McCray}, By T and Aronson, Alan R and {Scientist Allen Browne}, Computer C and Rindflesch, Thomas C and Razi, Amir and {Scientist Suresh Srinivasan}, Computer},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alexa McCray et al. - Unknown - UMLS{\textregistered} knowledge for biomedical language processing Computational Linguist(2).pdf:pdf},
journal = {Bulletin of the Medical Library Association},
title = {{UMLS{\textregistered} knowledge for biomedical language processing Computational Linguist}},
year = {1993}
}
@article{ali2013can,
author = {Ali, Tanveer and Schramm, David and Sokolova, Marina and Inkpen, Diana},
file = {::},
journal = {Ijcnlp},
keywords = {a more complex analysis,regarded as,s author and require,sentiment analysis is often,sentiments of the statement,than the factual ones,while emotional statements express},
number = {October},
pages = {667--673},
title = {{Can I Hear You? Sentiment Analysis on Medical Forums.}},
year = {2013}
}
@article{Aronson2010,
abstract = {MetaMap is a widely available program providing access to the concepts in the unified medical language system (UMLS) Metathesaurus from biomedical text. This study reports on MetaMap's evolution over more than a decade, concentrating on those features arising out of the research needs of the biomedical informatics community both within and outside of the National Library of Medicine. Such features include the detection of author-defined acronyms/abbreviations, the ability to browse the Metathesaurus for concepts even tenuously related to input text, the detection of negation in situations in which the polarity of predications is important, word sense disambiguation (WSD), and various technical and algorithmic features. Near-term plans for MetaMap development include the incorporation of chemical name recognition and enhanced WSD.},
author = {Aronson, Alan R and Lang, Fran{\c{c}}ois-Michel},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aronson, Lang - 2010 - An overview of MetaMap historical perspective and recent advances.pdf:pdf},
journal = {Journal of the American Medical Informatics Association},
title = {{An overview of MetaMap: historical perspective and recent advances}},
year = {2010}
}
@article{baccianella2010sentiwordnet,
author = {Baccianella, Stefano and Esuli, Andrea and Sebastiani, Fabrizio},
file = {::},
journal = {International Conference on Language Resources and Evaluation},
pages = {2200--2204},
title = {{SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining}},
volume = {10},
year = {2010}
}
@article{bao2015xay,
author = {Bảo, Hồ T{\'{u}}},
journal = {Tạp ch{\'{i}} Khoa học v{\`{a}} C{\^{o}}ng nghệ Việt Nam},
pages = {16--20},
title = {{X{\^{a}}y dựng v{\`{a}} khai th{\'{a}}c BAĐT: con đường mới trong kh{\'{a}}m chữa bệnh v{\`{a}} nghi{\^{e}}n cứu y học}},
year = {2015}
}
@article{benamara2012how,
abstract = {In this paper, we propose to study the effects of negation and modality on opinion expres-sions. Based on linguistic experiments in-formed by native speakers, we distill these ef-fects according to the type of modality and negation. We show that each type has a spe-cific effect on the opinion expression in its scope: both on the polarity and the strength for negation, and on the strength and/or the degree of certainty for modality. The empirical re-sults reported in this paper provide a basis for future opinion analysis systems that have to compute the sentiment orientation at the sen-tence or at the clause level. The methodology we used for deriving this basis was applied for French but it can be easily instantiated for other languages like English.},
author = {Benamara, Farah and Chardon, Baptiste and Mathieu, Yannick and Popescu, Vladimir and Asher, Nicholas},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Benamara et al. - 2012 - How do Negation and Modality Impact on Opinions.pdf:pdf},
pages = {10--18},
title = {{How do Negation and Modality Impact on Opinions?}},
year = {2012}
}
@book{bird2009natural,
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
publisher = {" O'Reilly Media, Inc."},
title = {{Natural language processing with Python}},
year = {2009}
}
@article{bobicev2011sentiment,
author = {Bobicev, Marina Sokolova Victoria},
file = {::},
journal = {Proceedings of Recent Advances in Natural Language Processing},
pages = {132--139},
title = {{Sentiments and Opinions in Health-related Web Messages}},
year = {2011}
}
@article{bobicev2012learning,
author = {Bobicev, Victoria and Sokolova, Marina and Jafer, Yasser and Schramm, David},
file = {::},
journal = {Advances in Artificial Intelligence},
pages = {37--48},
publisher = {Springer},
title = {{Learning sentiments from tweets with personal health information}},
year = {2012}
}
@article{Bodenreider2004,
abstract = {The Unified Medical Language System (http://umlsks.nlm.nih.gov) is a repository of biomedical vocabularies developed by the US National Library of Medicine. The UMLS integrates over 2 million names for some 900,000 concepts from more than 60 families of biomedical vocabularies, as well as 12 million relations among these concepts. Vocabularies integrated in the UMLS Metathesaurus include the NCBI taxonomy, Gene Ontology, the Medical Subject Headings (MeSH), OMIM and the Digital Anatomist Symbolic Knowledge Base. UMLS concepts are not only inter-related, but may also be linked to external resources such as GenBank. In addition to data, the UMLS includes tools for customizing the Metathesaurus (MetamorphoSys), for generating lexical variants of concept names (lvg) and for extracting UMLS concepts from text (MetaMap). The UMLS knowledge sources are updated quarterly. All vocabularies are available at no fee for research purposes within an institution, but UMLS users are required to sign a license agreement. The UMLS knowledge sources are distributed on CD-ROM and by FTP.},
author = {Bodenreider, Olivier},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bodenreider - 2004 - The Unified Medical Language System (UMLS) integrating biomedical terminology.pdf:pdf},
journal = {Nucleic acids research},
month = {jan},
pmid = {14681409},
publisher = {Oxford University Press},
title = {{The Unified Medical Language System (UMLS): integrating biomedical terminology.}},
volume = {32},
year = {2004}
}
@article{bridewell2001evaluation,
author = {Bridewell, Will and Hanbury, Paul},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bridewell, Hanbury - 2001 - Evaluation of Negation Phrases in Narrative Clinical Reports(3).pdf:pdf},
journal = {Proceedings of the American Medical Informatics Association Symposium},
pages = {105--109},
title = {{Evaluation of Negation Phrases in Narrative Clinical Reports}},
year = {2001}
}
@article{bui2014learning,
author = {Bui, Duy Duc An and Zeng-Treitler, Qing},
file = {::},
journal = {Journal of the American Medical Informatics Association},
number = {5},
pages = {850--857},
publisher = {The Oxford University Press},
title = {{Learning regular expressions for clinical text classification}},
volume = {21},
year = {2014}
}
@article{chandrakala2012opinion,
author = {Chandrakala, S and Sindhu, C},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chandrakala, Sindhu - 2012 - Opinion Mining and Sentiment Classification a Survey.pdf:pdf},
journal = {Information and Communications Technology Academy of Tamil Nadu Journal on Soft Computing},
number = {1},
pages = {420--425},
title = {{Opinion Mining and Sentiment Classification a Survey}},
volume = {3},
year = {2012}
}
@article{chapman2001evaluation,
abstract = {OBJECTIVE: Automatically identifying findings or diseases described in clinical textual reports requires determining whether clinical observations are present or absent. We evaluate the use of negation phrases and the frequency of negation in free-text clinical reports. METHODS: A simple negation algorithm was applied to ten types of clinical reports (n=42,160) dictated during July 2000. We counted how often each of 66 negation phrases was used to mark a clinical observation as absent. Physicians read a random sample of 400 sentences, and precision was calculated for the negation phrases. We measured what proportion of clinical observations were marked as absent. RESULTS: The negation algorithm was triggered by sixty negation phrases with just seven of the phrases accounting for 90{\%} of the negations. The negation phrases received an overall precision of 97{\%}, with "not" earning the lowest precision of 63{\%}. Between 39{\%} and 83{\%} of all clinical observations were identified as absent by the negation algorithm, depending on the type of report analyzed. The most frequently used clinical observations were negated the majority of the time. CONCLUSION: Because clinical observations in textual patient records are frequently negated, identifying accurate negation phrases is important to any system processing these reports.},
author = {Chapman, W W and Bridewell, W and Hanbury, P and Cooper, G F and Buchanan, B G},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chapman et al. - 2001 - Evaluation of negation phrases in narrative clinical reports.pdf:pdf},
journal = {Proceedings / AMIA ... Annual Symposium. AMIA Symposium},
keywords = {Algorithms,Computerized,Medical Records Systems,Unified Medical Language System},
pages = {105--9},
pmid = {11825163},
title = {{Evaluation of negation phrases in narrative clinical reports.}},
year = {2001}
}
@article{Chapman2013,
abstract = {We translated an existing English negation lexicon (NegEx) to Swedish, French, and German and compared the lexicon on corpora from each language. We observed Zipf's law for all languages, i.e., a few phrases occur a large number of times, and a large number of phrases occur fewer times. Negation triggers "no" and "not" were common for all languages; however, other triggers varied considerably. The lexicon is available in OWL and RDF format and can be extended to other languages. We discuss the challenges in translating negation triggers to other languages and issues in representing multilingual lexical knowledge.},
author = {Chapman, Wendy W and Hillert, Dieter and Velupillai, Sumithra and Kvist, Maria and Skeppstedt, Maria and Chapman, Brian E and Conway, Mike and Tharp, Melissa and Mowery, Danielle L and Deleger, Louise},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chapman et al. - 2013 - Extending the NegEx lexicon for multiple languages.pdf:pdf},
journal = {Studies in health technology and informatics},
pages = {677--81},
pmid = {23920642},
publisher = {NIH Public Access},
title = {{Extending the NegEx lexicon for multiple languages.}},
volume = {192},
year = {2013}
}
@inproceedings{choi2008learning,
author = {Choi, Yejin and Cardie, Claire},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
file = {::},
organization = {Association for Computational Linguistics},
pages = {793--801},
title = {{Learning with compositional semantics as structural inference for subsentential sentiment analysis}},
year = {2008}
}
@article{Cohen1960,
abstract = {"A coefficient of interjudge agreement for nominal scales, K = (P o - P c)/(1 - P c), is presented. It is directly interpretable as the proportion of joint judgments in which there is agreement, after chance agreement is excluded{\ldots} . The maximum value which k can take for any given problem is given, and the implications of this value to the question of agreement discussed." Standard error and techniques for estimation and hypothesis testing are presented.},
archivePrefix = {arXiv},
arxivId = {1011.1669v3},
author = {Cohen, Jacob},
eprint = {1011.1669v3},
file = {::},
journal = {Educational and Psychological Measurement},
pages = {37--46},
pmid = {49},
title = {{A coefficient of agreement for nominal scales}},
volume = {20},
year = {1960}
}
@incollection{costumero2014an,
abstract = {The adoption of hospital EHR technology is significantly growing and expected to grow. Digitalized information is the basis for health analytics. In particular, patient medical records contain valuable clinical information written in narrative form that can only be extracted after it has been previously preprocessed with Natural Language Processing techniques. An important challenge in clinical narrative text is that concepts commonly appear negated. Though worldwide there are nearly 500 million Spanish speakers, there seems to be no algorithm for negation detection in medical texts written in that language.$\backslash$r$\backslash$n$\backslash$r$\backslash$nThus this paper presents an approach to adapt the NegEx algorithm to be applied to detect negation regarding clinical conditions in Spanish written medical documents. Our algorithm has been trained with 500 texts where 422 different sentences and 267 unique clinical conditions were identified. It has been tested for negated terms showing an accuracy obtained is of 83,37{\%}. As in the detection of definite affirmed conditions, the results show an accuracy of 84,78{\%}.},
author = {Costumero, Roberto and Lopez, Federico and Gonzalo-Mart{\'{i}}n, Consuelo and Millan, Marta and Menasalvas, Ernestina},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
file = {::;::;:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/Brain Informatics and Health.pdf:pdf},
keywords = {Medical texts,Natural Language Processing,Negation Detection},
pages = {366--375},
publisher = {Springer International Publishing},
title = {{An approach to detect negation on medical documents in Spanish}},
volume = {8609 LNAI},
year = {2014}
}
@article{Councill2010,
abstract = {Automatic detection of linguistic negation in free text is a critical need for many text processing applications, including sentiment analysis. This paper presents a negation detection system based on a conditional random field modeled using features from an English dependency parser. The scope of negation detection is limited to explicit rather than implied negations within single sentences. A new negation corpus is presented that was constructed for the domain of English product reviews obtained from the open web, and the proposed negation extraction system is evaluated against the reviews corpus as well as the standard BioScope negation corpus, achieving 80.0{\%} and 75.5{\%} F1 scores, respectively. The impact of accurate negation detection on a state-of-the-art sentiment analysis system is also reported.},
author = {Councill, I G and McDonald, Ryan and Velikovich, Leonid},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/What Great and What Not.pdf:pdf},
journal = {Proceedings of the ACL Workshop on Negation and Speculation in Natural Language Processing Uppsala Sweden},
number = {July},
pages = {51--59},
title = {{What's great and what's not: learning to classify the scope of negation for improved sentiment analysis}},
year = {2010}
}
@article{CruzDiaz2015,
abstract = {PhD Thesis written by Noa P.},
author = {{Cruz D{\'{i}}az}, Noa P and {De Buenaga}, Manuel},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz D{\'{i}}az, De Buenaga - 2015 - Negation and Speculation Detection in Clinical and Review Texts Detecci{\'{o}}n de la Negaci{\'{o}}n y la Especulaci{\'{o}}.pdf:pdf},
journal = {Procesamiento  del  Lenguaje  Natural},
title = {{Negation and Speculation Detection in Clinical and Review Texts Detecci{\'{o}}n de la Negaci{\'{o}}n y la Especulaci{\'{o}}n en Textos M{\'{e}}dicos y de Opini{\'{o}}n}},
year = {2015}
}
@article{Cruz2016,
abstract = {(Open Nottingham OER report; survey of 51 undergraduates' use of OER.)},
author = {Cruz, Noa P. and Taboada, Maite and Mitkov, Ruslan},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/A machine-learning approach to negation and speculation detection for sentiment analysis.pdf:pdf},
journal = {Journal of the Association for Information Science and Technology},
keywords = {machine learning,natural language processing},
month = {sep},
number = {9},
pages = {2118--2136},
title = {{A machine-learning approach to negation and speculation detection for sentiment analysis}},
volume = {67},
year = {2016}
}
@article{denecke2015sentiment,
author = {Denecke, Kerstin},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Denecke - 2015 - Sentiment Analysis from Medical Texts.pdf:pdf},
journal = {Health Web Science},
pages = {75--81},
title = {{Sentiment Analysis from Medical Texts}},
year = {2015}
}
@article{Denecke2015,
author = {Denecke, Kerstin},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Denecke - 2015 - Sentiment Analysis from Medical Texts.pdf:pdf},
pages = {75--81},
title = {{Health Web Science}},
year = {2015}
}
@article{Denecke2015a,
abstract = {Objective: Clinical documents reflect a patient's health status in terms of observations and contain objective information such as descriptions of examination results, diagnoses and interventions. To evaluate this information properly, assessing positive or negative clinical outcomes or judging the impact of a medical condition on patient's well being are essential. Although methods of sentiment analysis have been developed to address these tasks, they have not yet found broad application in the medical domain. Methods and material: In this work, we characterize the facets of sentiment in the medical sphere and identify potential use cases. Through a literature review, we summarize the state of the art in healthcare settings. To determine the linguistic peculiarities of sentiment in medical texts and to collect open research questions of sentiment analysis in medicine, we perform a quantitative assessment with respect to word usage and sentiment distribution of a dataset of clinical narratives and medical social media derived from six different sources. Results: Word usage in clinical narratives differs from that in medical social media: Nouns predominate. Even though adjectives are also frequently used, they mainly describe body locations. Between 12{\%} and 15{\%} of sentiment terms are determined in medical social media datasets when applying existing sentiment lexicons. In contrast, in clinical narratives only between 5{\%} and 11{\%} opinionated terms were identified. This proves the less subjective use of language in clinical narratives, requiring adaptations to existing methods for sentiment analysis. Conclusions: Medical sentiment concerns the patient's health status, medical conditions and treatment. Its analysis and extraction from texts has multiple applications, even for clinical narratives that remained so far unconsidered. Given the varying usage and meanings of terms, sentiment analysis from medical documents requires a domain-specific sentiment source and complementary context-dependent features to be able to correctly interpret the implicit sentiment.},
annote = {Như l{\`{a}} bản nh{\'{a}}i của Heath Web Science},
author = {Denecke, Kerstin and Deng, Yihan},
file = {::},
journal = {Artificial Intelligence in Medicine},
keywords = {Clinical text mining,Health status analysis,Medical language processing,Sentiment analysis},
number = {1},
pages = {17--27},
pmid = {25982909},
publisher = {Elsevier B.V.},
title = {{Sentiment analysis in medical settings: New opportunities and challenges}},
volume = {64},
year = {2015}
}
@article{deng2014retrieving,
author = {Deng, Yihan and Stoehr, Matthaeus and Denecke, Kerstin},
file = {::},
journal = {Proceedings of the Medical Information Retrieval Workshop at Special Interest Group on Information Retrieval},
pages = {12--15},
title = {{Retrieving Attitudes: Sentiment Analysis from Clinical Narratives.}},
year = {2014}
}
@article{RN11,
author = {Duyệt, L{\^{e}} Văn and Nguy{\^{e}}n, Trần V{\~{o}} T{\^{a}}n and H{\`{u}}ng, T S Ng{\^{o}} Thanh},
file = {::},
title = {{Đ{\'{a}}nh gi{\'{a}} sản phẩm điện tử dựa tr{\^{e}}n nhận x{\'{e}}t của người d{\`{u}}ng tr{\^{e}}n internet.}},
type = {Journal Article},
year = {2015}
}
@article{RN12,
abstract = {BACKGROUND: Identification of negation in electronic health records is essential if we are to understand the computable meaning of the records: Our objective is to compare the accuracy of an automated mechanism for assignment of Negation to clinical concepts within a compositional expression with Human Assigned Negation. Also to perform a failure analysis to identify the causes of poorly identified negation (i.e. Missed Conceptual Representation, Inaccurate Conceptual Representation, Missed Negation, Inaccurate identification of Negation). METHODS: 41 Clinical Documents (Medical Evaluations; sometimes outside of Mayo these are referred to as History and Physical Examinations) were parsed using the Mayo Vocabulary Server Parsing Engine. SNOMED-C was used to provide concept coverage for the clinical concepts in the record. These records resulted in identification of Concepts and textual clues to Negation. These records were reviewed by an independent medical terminologist, and the results were tallied in a spreadsheet. Where questions on the review arose Internal Medicine Faculty were employed to make a final determination. RESULTS: SNOMED-CT was used to provide concept coverage of the 14,792 Concepts in 41 Health Records from John's Hopkins University. Of these, 1,823 Concepts were identified as negative by Human review. The sensitivity (Recall) of the assignment of negation was 97.2{\%} (p {\textless} 0.001, Pearson Chi-Square test; when compared to a coin flip). The specificity of assignment of negation was 98.8{\%}. The positive likelihood ratio of the negation was 81. The positive predictive value (Precision) was 91.2{\%} CONCLUSION: Automated assignment of negation to concepts identified in health records based on review of the text is feasible and practical. Lexical assignment of negation is a good test of true Negativity as judged by the high sensitivity, specificity and positive likelihood ratio of the test. SNOMED-CT had overall coverage of 88.7{\%} of the concepts being negated.},
author = {Elkin, Peter L and Brown, Steven H and Bauer, Brent a and Husser, Casey S and Carruth, William and Bergstrom, Larry R and Wahner-Roedler, Dietlind L},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Elkin et al. - 2005 - A controlled trial of automated classification of negation from clinical notes.pdf:pdf},
journal = {BMC medical informatics and decision making},
number = {1},
pages = {13},
pmid = {15876352},
title = {{A controlled trial of automated classification of negation from clinical notes.}},
type = {Journal Article},
volume = {5},
year = {2005}
}
@article{Elkin2005,
abstract = {BACKGROUND: Identification of negation in electronic health records is essential if we are to understand the computable meaning of the records: Our objective is to compare the accuracy of an automated mechanism for assignment of Negation to clinical concepts within a compositional expression with Human Assigned Negation. Also to perform a failure analysis to identify the causes of poorly identified negation (i.e. Missed Conceptual Representation, Inaccurate Conceptual Representation, Missed Negation, Inaccurate identification of Negation). METHODS: 41 Clinical Documents (Medical Evaluations; sometimes outside of Mayo these are referred to as History and Physical Examinations) were parsed using the Mayo Vocabulary Server Parsing Engine. SNOMED-C was used to provide concept coverage for the clinical concepts in the record. These records resulted in identification of Concepts and textual clues to Negation. These records were reviewed by an independent medical terminologist, and the results were tallied in a spreadsheet. Where questions on the review arose Internal Medicine Faculty were employed to make a final determination. RESULTS: SNOMED-CT was used to provide concept coverage of the 14,792 Concepts in 41 Health Records from John's Hopkins University. Of these, 1,823 Concepts were identified as negative by Human review. The sensitivity (Recall) of the assignment of negation was 97.2{\%} (p {\textless} 0.001, Pearson Chi-Square test; when compared to a coin flip). The specificity of assignment of negation was 98.8{\%}. The positive likelihood ratio of the negation was 81. The positive predictive value (Precision) was 91.2{\%} CONCLUSION: Automated assignment of negation to concepts identified in health records based on review of the text is feasible and practical. Lexical assignment of negation is a good test of true Negativity as judged by the high sensitivity, specificity and positive likelihood ratio of the test. SNOMED-CT had overall coverage of 88.7{\%} of the concepts being negated.},
author = {Elkin, Peter L and Brown, Steven H and Bauer, Brent a and Husser, Casey S and Carruth, William and Bergstrom, Larry R and Wahner-Roedler, Dietlind L},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Elkin et al. - 2005 - A controlled trial of automated classification of negation from clinical notes.pdf:pdf},
journal = {BMC medical informatics and decision making},
month = {may},
number = {1},
pages = {13},
pmid = {15876352},
publisher = {BioMed Central},
title = {{A controlled trial of automated classification of negation from clinical notes.}},
volume = {5},
year = {2005}
}
@article{Giachanou2016,
abstract = {Sentiment analysis in Twitter is a field that has recently attracted research interest. Twitter is one of the most popular microblog platforms on which users can publish their thoughts and opinions. Sentiment analysis in Twitter tackles the problem of analyzing the tweets in terms of the opinion they express. This survey provides an overview of the topic by investigating and briefly describing the algorithms that have been proposed for sentiment analysis in Twitter. The presented studies are categorized according to the approach they follow. In addition, we discuss fields related to sentiment analysis in Twitter including Twitter opinion retrieval, tracking sentiments over time, irony detection, emotion detection, and tweet sentiment quantification, tasks that have recently attracted increasing attention. Resources that have been used in the Twitter sentiment analysis literature are also briefly presented. The main contributions of this survey include the presentation of the proposed approaches for sentiment analysis in Twitter, their categorization according to the technique they use, and the discussion of recent research trends of the topic and its related fields.},
annote = {Tổng hợp c{\'{a}}c phương ph{\'{a}}p SA cho twitter:
- supervised learing: y{\^{e}}u cầu data training v{\`{a}} phải đủ lớn
- lexicon-based: ko y{\^{e}}u cầu data c{\'{o}} lable để train, dựa tr{\^{e}}n từ điển
- hybrid method: combine 2 phương ph{\'{a}}p tr{\^{e}}n
- graph-base method (semi-supervised learning)},
author = {Giachanou, Anastasia and Crestani, Fabio},
file = {::},
journal = {ACM Comput Surv},
keywords = {Additional Key Words and Phrases,CCS Concepts,Sentiment analysis,microblogs,opinion mining,r Information systems → Sentiment analysis,twitter},
number = {2},
pages = {Article 28; 1--41},
title = {{Like it or not: A survey of Twitter sentiment analysis methods}},
volume = {49},
year = {2016}
}
@article{gindl2006negation,
author = {Gindl, S},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Survey, Gindl - 2006 - Negation Detection in Automated Medical Applications.pdf:pdf},
keywords = {medical domain,negation},
number = {Asgaard-{\{}TR-2006-1{\}}},
pages = {1--28},
title = {{Negation Detection in Automated Medical Applications: A Survey}},
year = {2006}
}
@article{Gindl2008,
abstract = {In clinical practice guidelines (CPGs) the medical information is stored in a narrative way. A large part of this information occurs in a negated form. The detection of negation in CPGs is an important task since it helps medical personnel to identify not occurring symptoms and diseases as well as treatment actions that should not be accomplished. We developed algorithms capable of Negation Detection in this kind of medical documents. According to our results, we are convinced that the involvement of syntactical methods can improve Negation Detection, not only in medical writings but also in arbitrary narrative texts.},
author = {Gindl, Stefan and Kaiser, Katharina and Miksch, Silvia},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gindl, Kaiser, Miksch - 2008 - Syntactical negation detection in clinical practice guidelines.pdf:pdf},
journal = {Studies in health technology and informatics},
keywords = {clinical practice guidelines,natural language processing,negation detection},
pages = {187--192},
pmid = {18487729},
publisher = {Europe PMC Funders},
title = {{Europe PMC Funders Group Syntactical Negation Detection in Clinical Practice Guidelines}},
volume = {136},
year = {2010}
}
@incollection{Givon1993,
address = {Amsterdam},
author = {Giv{\'{o}}n, T.},
month = {jul},
publisher = {John Benjamins Publishing Company},
title = {{English Grammar}},
year = {1993}
}
@article{Goldin2003,
author = {Goldin, I and Chapman, WW},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/Learning to Detect Negation with `Not' in Medical Texts.pdf:pdf},
journal = {Proceedings of ACM-SIGIR 2003.},
number = {AUGUST 2003},
title = {{Learning to detect negation with 'not' in medical texts}},
year = {2003}
}
@article{gonccalves2013comparing,
author = {Gon{\c{c}}alves, Pollyanna and Ara{\'{u}}jo, Matheus and Benevenuto, Fabr$\backslash$'$\backslash$icio and Cha, Meeyoung},
file = {::},
journal = {Proceedings of the 14th Association for Computing Machinery International Conference on Online social networks},
pages = {27--38},
title = {{Comparing and combining sentiment analysis methods}},
year = {2013}
}
@inproceedings{hiroshi2004deeper,
author = {Hiroshi, Kanayama and Tetsuya, Nasukawa and Hideo, Watanabe},
booktitle = {Proceedings of the 20th international conference on Computational Linguistics},
file = {::},
organization = {Association for Computational Linguistics},
pages = {494},
title = {{Deeper sentiment analysis using machine translation technology}},
year = {2004}
}
@article{jagtap2013analysis,
author = {Jagtap, V S and Pawar, Karishma},
file = {::},
journal = {International Journal of Scientific Engineering and Technology},
number = {3},
pages = {164--170},
title = {{Analysis of different approaches to sentence-level sentiment classification}},
volume = {2},
year = {2013}
}
@article{joachims1998text,
author = {Joachims, Thorsten},
file = {::},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {137--142},
title = {{Text categorization with support vector machines: Learning with many relevant features}},
year = {1998}
}
@article{Kelleher2008,
author = {Kelleher, John D and Namee, Brian Mac},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelleher, Namee - 2008 - A Review of Negation in Clinical Texts DIT Technical Report SOC-AIG-001-08.pdf:pdf},
journal = {Artificial Intelligence},
pages = {1--8},
title = {{A Review of Negation in Clinical Texts : DIT Technical Report: SOC-AIG-001-08}},
year = {2008}
}
@article{kiss2006unsupervised,
author = {Kiss, Tibor and Strunk, Jan},
journal = {Computational Linguistics},
number = {4},
pages = {485--525},
publisher = {MIT Press},
title = {{Unsupervised multilingual sentence boundary detection}},
volume = {32},
year = {2006}
}
@article{Kumar2016,
annote = {N{\'{o}}i về feature selection, giải thuật tự động l{\`{a}}m},
author = {Kumar, Akshi and Khorwal, Renu and Chaudhary, Shweta},
file = {::},
keywords = {0 has changed the,comments,feature selection,feedbacks pertaining to,ideas,opinion mining,sentiment analysis,suggestions,swarm intelligence,swarm optimization,the tremendous growth of,views,views and opinions,way people express their,web 2},
number = {October},
title = {{A Survey on Sentiment Analysis using Swarm Intelligence}},
volume = {9},
year = {2016}
}
@inproceedings{Limsopatham2013,
abstract = {Negated language is frequently used by medical practition- ers to indicate that a patient does not have a given med- ical condition. Traditionally, information retrieval systems do not distinguish between the positive and negative con- texts of terms when indexing documents. For example, when searching for patients with angina, a retrieval system might wrongly consider a patient with a medical record stating “no evidence of angina”to be relevant. While it is possible to en- hance a retrieval system by taking into account the context of terms within the indexing representation of a document, some non-relevant medical records can still be ranked highly, if they include some of the query terms with the intended context. In this paper, we propose a novel learning frame- work that effectively handles negated language. Based on features related to the positive and negative contexts of a term, the framework learns how to appropriately weight the occurrences of the opposite context of any query term, thus preventing documents that may not be relevant from being retrieved. We thoroughly evaluate our proposed framework using the TREC 2011 and 2012 Medical Records track test collections. Our results show significant improvements over existing strong baselines. In addition, in combination with a traditional query expansion and a conceptual represen- tation approach, our proposed framework could achieve a retrieval effectiveness comparable to the performance of the best TREC 2011 and 2012 systems, while not addressing other challenges in medical records search, such as the ex- ploitation of semantic relationships between medical terms.},
address = {New York, New York, USA},
author = {Limsopatham, Nut and Macdonald, Craig and Ounis, Iadh},
booktitle = {Proceedings of the 22nd ACM international conference on Conference on information {\&} knowledge management - CIKM '13},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/Learning to Handle Negated Language in Medical Records Search.pdf:pdf},
keywords = {medical records search,negation,regression-},
pages = {1431--1440},
publisher = {ACM Press},
title = {{Learning to handle negated language in medical records search}},
year = {2013}
}
@article{liu2010sentiment,
author = {Liu, Bing},
file = {::},
journal = {Handbook of natural language processing},
pages = {627--666},
title = {{Sentiment Analysis and Subjectivity.}},
volume = {2},
year = {2010}
}
@book{liu2012sentiment,
annote = {Ph{\^{a}}n t{\'{i}}ch cảm x{\'{u}}c (khai ph{\'{a}} {\'{y}} kiến - opinion mining) gồm: {\'{y}} kiến, cảm x{\'{u}}c (sentiment), sự ước lượng (evaluations), appraisals (sự định gi{\'{a}}, đ{\'{a}}nh gi{\'{a}}), th{\'{a}}i độ (attitudes) 

1.2.1 C{\'{a}}c level:
- Document: chỉ d{\`{u}}ng cho c{\'{a}}c document n{\'{o}}i về 1 entity, document so s{\'{a}}nh th{\`{i}} ko d{\`{u}}ng đc
- Sentence: gần với ph{\^{a}}n t{\'{i}}ch chủ/kh{\'{a}}ch quan, tuy nhi{\^{e}}n chủ quan ko tương đương với sentiment bởi c{\^{a}}u kh{\'{a}}ch quan cũng c{\'{o}} thể c{\'{o}} sentiment ngầm {\'{y}} 
- Entity v{\`{a}} Aspect:
Một {\'{y}} kiến (opinion) gồm: cảm x{\'{u}}c (ti{\^{e}}u/t{\'{i}}ch) v{\`{a}} một mục ti{\^{e}}u (của {\'{y}} kiến đ{\'{o}}), vd: mặc d{\`{u}} dịch vụ th{\`{i}} ko đc tốt, t{\^{o}}i vẫn th{\'{i}}ch nh{\`{a}} h{\`{a}}ng n{\`{a}}y

Ngo{\`{a}}i ra, c{\'{o}} 2 loại {\'{y}} kiến:
1. Thường: c{\'{a}}i b{\'{a}}nh ngon
2. So s{\'{a}}nh: B{\'{a}}nh a ngon hơn b{\'{a}}nh b

1.2.2 Từ vựng cảm x{\'{u}}c
Tập hợp được c{\'{a}}c từ vựng n{\`{a}}y sẽ gi{\'{u}}p cho việc ph{\^{a}}n t{\'{i}}ch, nhưng vẫn sẽ ko đủ:
- một từ c{\'{o}} thể mang 2 sentiment kh{\'{a}}c nhau trong 2 ngữ cảnh kh{\'{a}}c nhau
- một c{\^{a}}u c{\'{o}} 1 từ chỉ sentiment chưa chắc đ{\~{a}} c{\'{o}} t{\'{i}}nh sentiment, vd như c{\^{a}}u hỏi, c{\^{a}}u đk. N{\'{o}}i như vậy ko c{\'{o}} nghĩa l{\`{a}} mọi c{\^{a}}u hỏi, c{\^{a}}u đk đều ko biểu lộ sentiment
- c{\^{a}}u ch{\^{a}}m biếm: thật l{\`{a}} 1 c{\'{a}}i xe tuyệt, n{\'{o}} đ{\~{a}} ko l{\`{a}}m việc 2 ng{\`{a}}y
- c{\^{a}}u ko c{\'{o}} từ sentiment vẫn biểu đạt {\'{y}} ti{\^{e}}u/t{\'{i}}ch

2.1.1 Đặt vấn đề:
- Một {\'{y}} kiến gồm 2 th{\`{a}}nh phần: target g v{\`{a}} sentiment s: (g,s)
g c{\'{o}} thể l{\`{a}} entity hoặc aspect of entity
s: pos, neg, neu, hoặc một số thực tr{\^{e}}n 1 thang đo
pos, neg, neu c{\`{o}}n gọi l{\`{a}} sentiment (opionion) orientation (polarirites)
- Nguồn của {\'{y}} kiến: 1 người, 2 người, ai ... (opinion sources/holders)
- Thời gian của {\'{y}} kiến

Vậy một opinion gồm: (g,s,h,t)
g: target, c{\'{o}} thể được decompose, v{\`{a}} được xem như entity với định nghĩa b{\^{e}}n dưới. Domain của g: sản phẩn, dịch vụ, tổ chức, c{\'{a}} thể, vấn đề, sự kiện, topic, v{\`{a}} những thuộc t{\'{i}}nh của ch{\'{u}}ng
s: sentiment
h: opinion holder
t: time

Entity: e(T,W)
T: hierarchy of part, sub-part,...
W: set of attributes of e

Gộp tất cả lại, ta c{\'{o}}:
(ei, aij, sijkl, hk, tl),
where ei is the name of an entity, aij is an aspect of ei, sijkl is the sentiment on aspect aij of entity ei, hk is the opinion holder, and tl is the time when the opinion is expressed by hk. The sentiment sijkl is positive, negative, or neutral

Một điểm lưu {\'{y}} l{\`{a}}: c{\'{a}}ch biểu diễn n{\`{a}}y c{\'{o}} thể g{\^{a}}y mất th{\^{o}}ng tin, v{\`{i}} sự đơn giản h{\'{o}}a vế đề (entity c{\`{o}}n 2 level)

2.1.2 Nhiệm vụ cụ thể (output)
Cho một opinion document d, x{\'{a}}c định 5 yếu tố tr{\^{e}}n
- X{\'{a}}c định entity
- X{\'{a}}c định aspect
-},
author = {Liu, Bing},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - 2012 - Sentiment Analysis and Opinion Mining(2).pdf:pdf},
title = {{Sentiment Analysis and Opinion Mining}},
year = {2012}
}
@article{manning2009anintroduction,
author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"{u}}tze, Hinrich},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Id - 2009 - An Introdution to Information Retrieval.pdf:pdf},
journal = {Journal Information Retrieval},
pages = {319--348},
title = {{An Introdution to Information Retrieval}},
year = {2009}
}
@book{marsland2015machine,
author = {Marsland, Stephen},
file = {::},
title = {{Machine Learning: An Algorithmic Perspective, Second Edition}},
year = {2015}
}
@article{Mata2008,
author = {Mata, Jacinto and Ma{\~{n}}a, Manuel J and Berm{\'{u}}dez, Jos{\'{e}} M and Cruz, Noa P and Jim{\'{e}}nez, Patricia},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mata et al. - 2008 - Handling Negation in Classification of Clinical Texts.pdf:pdf},
journal = {Conference: AMIA Workshop on Challenges in Natural Language Processing for Clinical Data},
title = {{Handling Negation in Classification of Clinical Texts}},
year = {2008}
}
@article{Mate2016,
abstract = {In today's world, internet is the main origin of information. There are many ecommerce websites available where people discuss on different issues of product. All ecommerce website provide facility to the consumer to give opinion about their product and services. Consumer reviews contain rich and valuable knowledge for both firms and users. The problem with this information is that these reviews are mostly unorganized therefore creating difficulty for information transfer knowledge accession. We propose a product aspect ranking framework, which automatically determine the important aspects of products from online consumer reviews, aiming at improving the usability of the countless reviews. The important aspects are identified by two observations, a) The important aspects of a product are usually given by a large number of consumers; b) And consumers' opinions on the important aspects influence their overall opinions on the product. However Identifying important product aspects will increase the usability of numerous reviews and is useful to both consumers and firms. It is impractical for people to manually identify the important aspects of products from numerous reviews. Consumers can conveniently make purchasing decision by paying more attention to the important aspects, while enterprise can focus on improving the quality of these aspects and thus enhance product ranking effectively},
annote = {Ko đ{\'{a}}ng ch{\'{u}} {\'{y}}, n{\'{o}}i về ph{\^{a}}n t{\'{i}}ch sentiment tr{\^{e}}n aspect},
author = {Mate, Chetan},
file = {::},
journal = {International Research Journal of Engineering and Technology},
pages = {124--128},
title = {{Product Aspect Ranking using Sentiment Analysis: A Survey}},
year = {2016}
}
@article{medhat2014sentiment,
author = {Medhat, Walaa and Hassan, Ahmed and Korashy, Hoda},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Medhat, Hassan, Korashy - 2014 - Sentiment analysis algorithms and applications A survey(2).pdf:pdf},
journal = {Ain Shams Engineering Journal},
number = {4},
pages = {1093--1113},
publisher = {Elsevier},
title = {{Sentiment analysis algorithms and applications: A survey}},
volume = {5},
year = {2014}
}
@article{Mutalik2001,
abstract = {OBJECTIVES: To test the hypothesis that most instances of negated concepts in dictated medical documents can be detected by a strategy that relies on tools developed for the parsing of formal (computer) languages-specifically, a lexical scanner ("lexer") that uses regular expressions to generate a finite state machine, and a parser that relies on a restricted subset of context-free grammars, known as LALR(1) grammars. METHODS: A diverse training set of 40 medical documents from a variety of specialties was manually inspected and used to develop a program (Negfinder) that contained rules to recognize a large set of negated patterns occurring in the text. Negfinder's lexer and parser were developed using tools normally used to generate programming language compilers. The input to Negfinder consisted of medical narrative that was preprocessed to recognize UMLS concepts: the text of a recognized concept had been replaced with a coded representation that included its UMLS concept ID. The program generated an index with one entry per instance of a concept in the document, where the presence or absence of negation of that concept was recorded. This information was used to mark up the text of each document by color-coding it to make it easier to inspect. The parser was then evaluated in two ways: 1) a test set of 60 documents (30 discharge summaries, 30 surgical notes) marked-up by Negfinder was inspected visually to quantify false-positive and false-negative results; and 2) a different test set of 10 documents was independently examined for negatives by a human observer and by Negfinder, and the results were compared. RESULTS: In the first evaluation using marked-up documents, 8,358 instances of UMLS concepts were detected in the 60 documents, of which 544 were negations detected by the program and verified by human observation (true-positive results, or TPs). Thirteen instances were wrongly flagged as negated (false-positive results, or FPs), and the program missed 27 instances of negation (false-negative results, or FNs), yielding a sensitivity of 95.3 percent and a specificity of 97.7 percent. In the second evaluation using independent negation detection, 1,869 concepts were detected in 10 documents, with 135 TPs, 12 FPs, and 6 FNs, yielding a sensitivity of 95.7 percent and a specificity of 91.8 percent. One of the words "no," "denies/denied," "not," or "without" was present in 92.5 percent of all negations. CONCLUSIONS: Negation of most concepts in medical narrative can be reliably detected by a simple strategy. The reliability of detection depends on several factors, the most important being the accuracy of concept matching.},
author = {Mutalik, P G and Deshpande, A and Nadkarni, P M},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mutalik, Deshpande, Nadkarni - 2001 - Use of general-purpose negation detection to augment concept indexing of medical documents a quant.pdf:pdf},
journal = {Journal of the American Medical Informatics Association},
keywords = {*Medical Records,*Software,*Unified Medical Language System,Abstracting and Indexing as Topic/*methods,Information Storage and Retrieval,Natural Language Processing,Programming Languages},
number = {6},
pages = {598--609},
pmid = {11687566},
publisher = {American Medical Informatics Association},
title = {{Use of general-purpose negation detection to augment concept indexing of medical documents: a quantitative study using the UMLS}},
volume = {8},
year = {2001}
}
@article{na2012sentiment,
author = {Na, Jin-Cheon and Kyaing, Wai Yan Min and Khoo, Christopher S G and Foo, Schubert and Chang, Yun-Ke and Theng, Yin-Leng},
file = {::},
journal = {Proceedings of the 14th International Conference on Asia-Pacific Digital Librabries},
pages = {189--198},
title = {{Sentiment classification of drug reviews using a rule-based linguistic approach}},
year = {2012}
}
@article{Nakov2016,
abstract = {This paper discusses the fourth year of the " Sentiment Analysis in Twitter Task " . SemEval-2016 Task 4 comprises five sub-tasks, three of which represent a significant departure from previous editions. The first two subtasks are reruns from prior years and ask to predict the overall sentiment, and the sentiment towards a topic in a tweet. The three new subtasks focus on two variants of the basic " sentiment classification in Twitter " task. The first variant adopts a five-point scale, which confers an ordinal character to the clas-sification task. The second variant focuses on the correct estimation of the prevalence of each class of interest, a task which has been called quantification in the supervised learn-ing literature. The task continues to be very popular, attracting a total of 43 teams.},
annote = {Đ{\'{u}}c kết xu hướng c{\'{a}}c phương ph{\'{a}}p đc x{\`{a}}i trong lĩnh vực ph{\^{a}}n t{\'{i}}ch sentiment},
author = {Nakov, Preslav and Ritter, Alan and Rosenthal, Sara and Stoyanov, Veselin and Sebastiani, Fabrizio},
file = {::},
journal = {Proceedings of the 10th International Workshop on Semantic Evaluation},
title = {{SemEval-2016 Task 4: Sentiment Analysis in Twitter}},
year = {2016}
}
@inproceedings{Nasukawa:2003:SAC:945645.945658,
address = {New York, NY, USA},
author = {Nasukawa, Tetsuya and Yi, Jeonghee},
booktitle = {Proceedings of the 2Nd International Conference on Knowledge Capture},
file = {::},
keywords = {favorability analysis,information extraction,sentiment analysis,text mining},
pages = {70--77},
publisher = {ACM},
series = {K-CAP '03},
title = {{Sentiment Analysis: Capturing Favorability Using Natural Language Processing}},
year = {2003}
}
@incollection{Nguyen2004,
abstract = {Trong thời gian gần đ{\^{a}}y, một cuộc c{\'{a}}ch mạng {\^{a}}m thầm đ{\~{a}} v{\`{a}} đang xảy ra trong thế giới y khoa. Cuộc c{\'{a}}ch mạng n{\`{a}}y c{\'{o}} t{\^{e}}n l{\`{a}} "Evidence-based medicine" (m{\`{a}} người viết tạm dịch l{\`{a}} "Y học thực chứng"). Y học thực chứng l{\`{a}} g{\`{i}}? Phong tr{\`{a}}o n{\`{a}}y c{\'{o}} ảnh hưởng g{\`{i}} đến bệnh nh{\^{a}}n? B{\`{a}}i viết ngắn n{\`{a}}y c{\'{o}} mục đ{\'{i}}ch trả lời hai c{\^{a}}u hỏi đ{\'{o}}, v{\`{a}} thảo luận một số vấn đề li{\^{e}}n quan đến phong tr{\`{a}}o y học thực chứng. M{\^{o}} h{\`{i}}nh Aristotle v{\`{a}} vấn đề C{\'{o}} thể n{\'{o}}i rằng trong nhiều thế kỉ qua v{\`{a}} ngay cả ng{\`{a}}y nay, qu{\'{a}} tr{\`{i}}nh v{\`{a}} phương ph{\'{a}}p chẩn đo{\'{a}}n cũng như chữa trị bệnh tật được tiến h{\`{a}}nh theo m{\^{o}} h{\`{i}}nh của Aristotle. Theo m{\^{o}} h{\`{i}}nh n{\`{a}}y, người thầy thuốc đứng trước một người bệnh trước hết t{\`{i}}m hiểu căn bệnh, rồi đi đến một chẩn đo{\'{a}}n, v{\`{a}} sau đ{\'{o}} l{\`{a}} quyết định một phương ph{\'{a}}p điều trị, hoặc l{\`{a}} giải phẫu, dược liệu, hay t{\^{a}}m l{\'{i}} trị liệu. Nếu phản ứng sau khi chữa trị được đ{\'{a}}nh gi{\'{a}} l{\`{a}} t{\'{i}}ch cực th{\`{i}} chẩn đo{\'{a}}n v{\`{a}} phương ph{\'{a}}p chữa trị được xem l{\`{a}} đ{\'{u}}ng. Thoạt đầu mới nghe qua th{\`{i}} m{\^{o}} h{\`{i}}nh n{\`{a}}y kh{\^{o}}ng c{\'{o}} g{\`{i}} sai v{\`{a}} c{\'{o}} thể n{\'{o}}i l{\`{a}} rất hợp l{\'{i}}. Thực ra, m{\^{o}} h{\`{i}}nh l{\`{a}}m việc n{\`{a}}y đ{\~{a}} từng được ứng dụng th{\`{a}}nh c{\^{o}}ng trong y khoa từ bấy l{\^{a}}u nay. Chẳng hạn như khi Frederick G. Banting v{\`{a}} Charles H. Best (hai nh{\`{a}} khoa học người Canada) ph{\'{a}}t hiện vai tr{\`{o}} v{\`{a}} ảnh hưởng của sự thiếu hụt insulin trong c{\'{a}}c trường hợp tiểu đường trong thiếu ni{\^{e}}n th{\`{i}} phương ph{\'{a}}p điều trị cũng nằm ngay trong ph{\'{a}}t hiện đ{\'{o}}, tức l{\`{a}} thay thế insulin. Phương ph{\'{a}}p n{\`{a}}y đem lại nhiều th{\`{a}}nh c{\^{o}}ng ngoạn mục trong y khoa. M{\^{o}} h{\`{i}}nh của Banting v{\`{a}} Best cũng l{\`{a}} m{\^{o}} h{\`{i}}nh của tiến bộ của y học trong suốt thế kỉ 20. Nhưng con người n{\'{o}}i chung v{\`{a}} giới thầy thuốc n{\'{o}}i ri{\^{e}}ng thường c{\'{o}} khuynh hướng tiếp nhận những g{\`{i}} m{\`{a}} họ muốn tiếp nhận. N{\'{o}}i một c{\'{a}}ch kh{\'{a}}c, ch{\'{u}}ng ta thường c{\'{o}} khuynh hướng chủ quan. Nếu theo một gi{\'{a}}c quan th{\^{o}}ng thường n{\`{a}}o đ{\'{o}}, một phương ph{\'{a}}p điều trị sẽ c{\'{o}} hiệu nghiệm, th{\`{i}} b{\'{a}}c sĩ sẽ cảm nhận rằng phương ph{\'{a}}p đ{\'{o}} thực sự c{\'{o}} hiệu nghiệm, d{\`{u}} bằng chứng khoa học cho thấy ngược lại.},
author = {Nguyễn, Tuấn},
booktitle = {Hai mặt s{\'{a}}ng tối của y học hiện đại},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyễn - 2004 - Y học thực chứng v{\`{a}}i n{\'{e}}t kh{\'{a}}i qu{\'{a}}t.pdf:pdf},
title = {{Y học thực chứng: v{\`{a}}i n{\'{e}}t kh{\'{a}}i qu{\'{a}}t}},
year = {2004}
}
@incollection{Nguyen2004a,
abstract = {Trong thời gian gần đ{\^{a}}y, một cuộc c{\'{a}}ch mạng {\^{a}}m thầm đ{\~{a}} v{\`{a}} đang xảy ra trong thế giới y khoa. Cuộc c{\'{a}}ch mạng n{\`{a}}y c{\'{o}} t{\^{e}}n l{\`{a}} "Evidence-based medicine" (m{\`{a}} người viết tạm dịch l{\`{a}} "Y học thực chứng"). Y học thực chứng l{\`{a}} g{\`{i}}? Phong tr{\`{a}}o n{\`{a}}y c{\'{o}} ảnh hưởng g{\`{i}} đến bệnh nh{\^{a}}n? B{\`{a}}i viết ngắn n{\`{a}}y c{\'{o}} mục đ{\'{i}}ch trả lời hai c{\^{a}}u hỏi đ{\'{o}}, v{\`{a}} thảo luận một số vấn đề li{\^{e}}n quan đến phong tr{\`{a}}o y học thực chứng. M{\^{o}} h{\`{i}}nh Aristotle v{\`{a}} vấn đề C{\'{o}} thể n{\'{o}}i rằng trong nhiều thế kỉ qua v{\`{a}} ngay cả ng{\`{a}}y nay, qu{\'{a}} tr{\`{i}}nh v{\`{a}} phương ph{\'{a}}p chẩn đo{\'{a}}n cũng như chữa trị bệnh tật được tiến h{\`{a}}nh theo m{\^{o}} h{\`{i}}nh của Aristotle. Theo m{\^{o}} h{\`{i}}nh n{\`{a}}y, người thầy thuốc đứng trước một người bệnh trước hết t{\`{i}}m hiểu căn bệnh, rồi đi đến một chẩn đo{\'{a}}n, v{\`{a}} sau đ{\'{o}} l{\`{a}} quyết định một phương ph{\'{a}}p điều trị, hoặc l{\`{a}} giải phẫu, dược liệu, hay t{\^{a}}m l{\'{i}} trị liệu. Nếu phản ứng sau khi chữa trị được đ{\'{a}}nh gi{\'{a}} l{\`{a}} t{\'{i}}ch cực th{\`{i}} chẩn đo{\'{a}}n v{\`{a}} phương ph{\'{a}}p chữa trị được xem l{\`{a}} đ{\'{u}}ng. Thoạt đầu mới nghe qua th{\`{i}} m{\^{o}} h{\`{i}}nh n{\`{a}}y kh{\^{o}}ng c{\'{o}} g{\`{i}} sai v{\`{a}} c{\'{o}} thể n{\'{o}}i l{\`{a}} rất hợp l{\'{i}}. Thực ra, m{\^{o}} h{\`{i}}nh l{\`{a}}m việc n{\`{a}}y đ{\~{a}} từng được ứng dụng th{\`{a}}nh c{\^{o}}ng trong y khoa từ bấy l{\^{a}}u nay. Chẳng hạn như khi Frederick G. Banting v{\`{a}} Charles H. Best (hai nh{\`{a}} khoa học người Canada) ph{\'{a}}t hiện vai tr{\`{o}} v{\`{a}} ảnh hưởng của sự thiếu hụt insulin trong c{\'{a}}c trường hợp tiểu đường trong thiếu ni{\^{e}}n th{\`{i}} phương ph{\'{a}}p điều trị cũng nằm ngay trong ph{\'{a}}t hiện đ{\'{o}}, tức l{\`{a}} thay thế insulin. Phương ph{\'{a}}p n{\`{a}}y đem lại nhiều th{\`{a}}nh c{\^{o}}ng ngoạn mục trong y khoa. M{\^{o}} h{\`{i}}nh của Banting v{\`{a}} Best cũng l{\`{a}} m{\^{o}} h{\`{i}}nh của tiến bộ của y học trong suốt thế kỉ 20. Nhưng con người n{\'{o}}i chung v{\`{a}} giới thầy thuốc n{\'{o}}i ri{\^{e}}ng thường c{\'{o}} khuynh hướng tiếp nhận những g{\`{i}} m{\`{a}} họ muốn tiếp nhận. N{\'{o}}i một c{\'{a}}ch kh{\'{a}}c, ch{\'{u}}ng ta thường c{\'{o}} khuynh hướng chủ quan. Nếu theo một gi{\'{a}}c quan th{\^{o}}ng thường n{\`{a}}o đ{\'{o}}, một phương ph{\'{a}}p điều trị sẽ c{\'{o}} hiệu nghiệm, th{\`{i}} b{\'{a}}c sĩ sẽ cảm nhận rằng phương ph{\'{a}}p đ{\'{o}} thực sự c{\'{o}} hiệu nghiệm, d{\`{u}} bằng chứng khoa học cho thấy ngược lại.},
author = {Nguyễn, Tuấn},
booktitle = {Hai mặt s{\'{a}}ng tối của y học hiện đại},
title = {{Y học thực chứng: v{\`{a}}i n{\'{e}}t kh{\'{a}}i qu{\'{a}}t}},
year = {2004}
}
@article{niu2006using,
author = {Niu, Yun and Zhu, Xiaodan and Hirst, Graeme},
file = {::},
journal = {Proceedings of the American Medical Informatics Association Symposium},
pages = {599--603},
title = {{Using Outcome Polarity in Sentence Extraction for Medical Question-Answering}},
year = {2006}
}
@article{niu2005analysis,
author = {Niu, Yun and Zhu, Xiaodan and Li, Jianhua and Hirst, Graeme},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Niu et al. - 2005 - Analysis of Polarity Information in Medical Text.pdf:pdf},
journal = {Proceedings of the American Medical Informatics Association Symposium},
pages = {570--574},
title = {{Analysis of Polarity Information in Medical Text}},
year = {2005}
}
@inproceedings{ohana2009sentiment,
author = {Ohana, Bruno and Tierney, Brendan},
booktitle = {9th. IT {\&} T Conference},
file = {::},
pages = {13},
title = {{Sentiment classification of reviews using SentiWordNet}},
year = {2009}
}
@article{pang2008opinion,
author = {Pang, Bo and Lee, Lillian},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pang, Lee - 2008 - Opinion mining and sentiment analysis.pdf:pdf},
journal = {Foundations and trends in information retrieval},
number = {1-2},
pages = {1--135},
publisher = {Now Publishers Inc.},
title = {{Opinion mining and sentiment analysis}},
volume = {2},
year = {2008}
}
@article{pang2002thumbs,
author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
file = {::},
journal = {Proceedings of the 2nd Association for Computational Linguistics Conference on Empirical methods in Natural Language Processing},
pages = {79--86},
title = {{Thumbs Up?: Sentiment Classification Using Machine Learning Techniques}},
volume = {10},
year = {2002}
}
@article{scikit-learn,
author = {Pedregosa, F and Varoquaux, G and Gramfort, A and Michel, V and Thirion, B and Grisel, O and Blondel, M and Prettenhofer, P and Weiss, R and Dubourg, V and Vanderplas, J and Passos, A and Cournapeau, D and Brucher, M and Perrot, M and Duchesnay, E},
journal = {Journal of Machine Learning Research},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
volume = {12},
year = {2011}
}
@article{Pei2012,
abstract = {The paper presents an indoor navigation solution by combining physical motion recognition with wireless positioning. Twenty-seven simple features are extracted from the built-in accelerometers and magnetometers in a smartphone. Eight common motion states used during indoor navigation are detected by a Least Square-Support Vector Machines (LS-SVM) classification algorithm, e.g., static, standing with hand swinging, normal walking while holding the phone in hand, normal walking with hand swinging, fast walking, U-turning, going up stairs, and going down stairs. The results indicate that the motion states are recognized with an accuracy of up to 95.53{\%} for the test cases employed in this study. A motion recognition assisted wireless positioning approach is applied to determine the position of a mobile user. Field tests show a 1.22 m mean error in "Static Tests" and a 3.53 m in "Stop-Go Tests".},
author = {Pei, Ling and Liu, Jingbin and Guinness, Robert and Chen, Yuwei and Kuusniemi, Heidi and Chen, Ruizhi},
file = {::},
journal = {Sensors (Basel, Switzerland)},
keywords = {LS-SVM,indoor navigation,motion recognition,positioning,smartphone,wireless},
number = {5},
pages = {6155--75},
pmid = {22778635},
publisher = {Multidisciplinary Digital Publishing Institute  (MDPI)},
title = {{Using LS-SVM based motion recognition for smartphone indoor wireless positioning.}},
volume = {12},
year = {2012}
}
@article{pestian2012sentie,
author = {Pestian, John and Pestian, John and {Pawel Matykiewicz} and {Brett South} and {Ozlem Uzuner} and {John Hurdle}},
file = {::},
journal = {Biomedical Informatics Insights},
pages = {3--16},
title = {{Sentiment Analysis of Suicide Notes: A Shared Task}},
volume = {5},
year = {2012}
}
@article{porter1980analgorithm,
author = {Porter, M.F.},
file = {::},
journal = {Program: Electronic Library and Information Systems},
pages = {130--137},
title = {{An Algorithm for Suffix Stripping}},
volume = {14},
year = {1980}
}
@article{qu2008sentence,
author = {Qu, Lizhen and Toprak, Cigdem and Jakob, Niklas and Gurevych, Iryna},
file = {::},
journal = {Proceedings of the 7th National Institute of Informatics Testbeds and Community for Information Access Research Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering, and Cross-Lingual Information Acc},
pages = {210--217},
title = {{Sentence Level Subjectivity and Sentiment Analysis Experiments in NTCIR-7 MOAT Challenge}},
year = {2008}
}
@article{Reckman2013,
author = {Reckman, Hilke and Baird, Cheyanne and Crawford, Jean and Crowell, Richard and Micciulla, Linnea and Sethi, Saratendu and Veress, Fruzsina},
file = {::},
journal = {Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)},
number = {SemEval},
pages = {513--519},
title = {{teragram: Rule-based detection of sentiment phrases using SAS Sentiment Analysis}},
volume = {2},
year = {2013}
}
@article{Rokach2008,
author = {Rokach, Lior and Romano, Roni and Maimon, Oded},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/Negation Recognition in Medical Narrative Reports.pdf:pdf},
journal = {Information Retrieval},
keywords = {Artificial intelligence,Narrative medical reports,Negation,Part-of-speech tagging,Text classification},
month = {dec},
number = {6},
pages = {499--538},
publisher = {Kluwer Academic Publishers},
title = {{Negation recognition in medical narrative reports}},
volume = {11},
year = {2008}
}
@article{rokach2008negation,
author = {Rokach, Lior and Romano, Roni and Maimon, Oded},
file = {:C$\backslash$:/Users/Flynn/Dropbox/Luan-van-tot-nghiep/NegExPaper/Negation Recognition in Medical Narrative Reports.pdf:pdf},
journal = {Journal Information Retrieval},
pages = {499--538},
title = {{Negation Recognition in Medical Narrative Reports}},
volume = {11},
year = {2008}
}
@article{rooksby2001clinical,
author = {Rooksby, John and Kay, Stephen},
file = {::},
journal = {Studies in health technology and informatics},
number = {1},
pages = {680--684},
publisher = {IOS Press; 1999},
title = {{Clinical narrative and clinical organisation: properties of radiology reports}},
year = {2001}
}
@book{Rosenthal2015,
abstract = {In this paper, we describe the 2015 iteration of the SemEval shared task on Sentiment Analysis in Twitter. This was the most popular sentiment analysis shared task to date with more than 40 teams participating in each of the last three years. This year's shared task competition consisted of five sentiment prediction subtasks. Two were reruns from previous years: (A) sentiment expressed by a phrase in the context of a tweet, and (B) overall sentiment of a tweet. We further included three new subtasks asking to predict (C) the sentiment to- wards a topic in a single tweet, (D) the overall sentiment towards a topic in a set of tweets, and (E) the degree of prior polarity of a phrase. 1},
author = {Rosenthal, Sara and Nakov, Preslav and Kiritchenko, Svetlana and Mohammad, Saif M. and Ritter, Alan and Stoyanov, Veselin},
booktitle = {Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)},
file = {::},
pages = {451--463},
title = {{SemEval-2015 The 9th International Workshop on Semantic Evaluation}},
year = {2015}
}
@article{Russell2004,
author = {Russell and Bertrand},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Russell, Bertrand - 2004 - Negative and positive polarity items.pdf:pdf},
journal = {Linguistics {\&} Philosophy Mind London: Routledge. Zwarts},
number = {59},
pages = {479--493},
publisher = {The MIT Press Kluwer Elena Herburger},
title = {{Negative and positive polarity items}},
volume = {14},
year = {2004}
}
@article{sackett1996evidence,
author = {Sackett, David L and Rosenberg, William M C and Gray, J A Muir and Haynes, R Brian and Richardson, W Scott},
file = {::},
journal = {Bmj},
number = {7023},
pages = {71--72},
publisher = {British Medical Journal Publishing Group},
title = {{Evidence based medicine: what it is and what it isn't}},
volume = {312},
year = {1996}
}
@article{sarker2011outcome,
author = {Sarker, Abeed and Moll{\'{a}}-Aliod, Diego and Paris, C{\'{e}}cile and Others},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarker et al. - 2011 - Outcome Polarity Identification of Medical Papers.pdf:pdf},
journal = {Proceedings of Australasian Language Technology Association Workshop},
pages = {105--144},
title = {{Outcome Polarity Identification of Medical Papers}},
year = {2011}
}
@article{seki2008overview,
author = {Seki, Yohei and Evans, David K and Ku, Lun-Wei and Sun, Le and Chen, Hsin-Hsi and Kando, Noriko},
file = {::},
journal = {Proceedings National Institute of Informatics Testbeds and Community for Information Access Research Workshop Meeting in Tokyo},
pages = {185--203},
title = {{Overview of multilingual opinion analysis task at NTCIR-7}},
volume = {1},
year = {2008}
}
@article{Silva2015,
abstract = {Twitter is a microblogging platform in which users can post status messages, called “tweets,” to their friends. It has provided an enormous dataset of the so-called sentiments, whose classification can take place through supervised learning. To build supervised learning models, classification algorithms require a set of representative labeled data. However, labeled data are usually difficult and expensive to obtain, which motivates the interest in semi-supervised learning. This type of learning uses unlabeled data to complement the information provided by the labeled data in the training process; therefore, it is particularly useful in applications including tweet sentiment analysis, where a huge quantity of unlabeled data is accessible. Semi-supervised learning for tweet sentiment analysis, although appealing, is relatively new. We provide a comprehensive survey of semi-supervised approaches applied to tweet classification. Such approaches consist of graph-based, wrapper-based, and topic-based methods. A comparative study of algorithms based on self-training, co-training, topic modeling, and distant supervision highlights their biases and sheds light on aspects that the practitioner should consider in real-world applications.},
annote = {Semi-supervisor learning
- C{\'{o}} t{\'{o}}m tắt sơ về supervisor v{\`{a}} unsupervisor},
author = {Silva, Nadia Felix Felipe Da and Coletta, Luiz Fernando Sommaggio and Hruschka, Eduardo Raul},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva, Coletta, Hruschka - 2015 - A Survey and Comparative Study of Tweet Sentiment Analysis via Semi-Supervised Learning(3).pdf:pdf},
journal = {ACM Computing Surveys},
number = {1},
pages = {1--26},
title = {{A Survey and Comparative Study of Tweet Sentiment Analysis via Semi-Supervised Learning}},
volume = {49},
year = {2015}
}
@article{skeppstedt2016marker,
abstract = {Conditional random fields were trained to detect marker words for negation and speculation in two corpora belonging to two very different domains: clinical text and consumer review text. For the corpus of clinical text, marker words for specula-tion and negation were detected with re-sults in line with previously reported inter-annotator agreement scores. This was also the case for speculation markers in the consumer review corpus, while detection of negation markers was unsuccessful in this genre. Also a setup in which mod-els were trained on markers in consumer reviews, and applied on the clinical text genre, yielded low results. This shows that neither the trained models, nor the choice of appropriate machine learning al-gorithms and features, were transferable across the two text genres.},
author = {Skeppstedt, Maria and Paradis, Carita and Kerren, Andreas},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Skeppstedt, Paradis, Kerren - Unknown - Marker words for negation and speculation in health records and consumer reviews.pdf:pdf},
journal = {Proceedings of the 7th International Symposium on Semantic Mining in Biomedicine},
pages = {64--69},
title = {{Marker words for negation and speculation in health records and consumer reviews}},
volume = {1650},
year = {2016}
}
@inproceedings{smith2012cross,
author = {Smith, Phillip and Lee, Mark},
booktitle = {Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis},
file = {::},
organization = {Association for Computational Linguistics},
pages = {79--83},
title = {{Cross-discourse development of supervised sentiment analysis in the clinical domain}},
year = {2012}
}
@article{taboada2011lexicon,
annote = {1. Pang, Lee, and Vaithyanathan (2002) found that their machine-learning classifier
performed better when a binary feature was used indicating the presence of a unigram in the text, instead of a numerical feature indicating the number of appearances},
author = {Taboada, Maite and Brooke, Julian and Tofiloski, Milan and Voll, Kimberly and Stede, Manfred},
file = {::},
journal = {Association for Computational Linguistics},
number = {2},
pages = {267--307},
title = {{Lexicon-Based Methods for Sentiment Analysis}},
volume = {37},
year = {2011}
}
@article{Tanushi2013,
abstract = {Negation detection is a key component in clinical information extraction systems, as health record text contains reasonings in which the physician excludes different diagnoses by negating them. Many systems for negation detection rely on negation cues (e.g. not), but only few studies have investigated if the syntactic structure of the sentences can be used for determining the scope of these cues. We have in this paper compared three different systems for negation detection in Swedish clinical text (NegEx, PyConTextNLP and SynNeg), which have different approaches for determining the scope of negation cues. NegEx uses the distance between the cue and the disease, PyConTextNLP relies on a list of conjunctions limiting the scope of a cue, and in SynNeg the boundaries of the sentence units, provided by a syntactic parser, limit the scope of the cues. The three systems produced similar results, detecting negation with an F-score of around 80{\%}, but using a parser had advantages when handling longer, complex sentences or short sentences with contradictory statements.},
author = {Tanushi, Hideyuki and Dalianis, Hercules and Duneld, Martin and Kvist, Maria and Skeppstedt, Maria and Velupillai, Sumithra},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tanushi et al. - 2013 - Negation Scope Delimitation in Clinical Text Using Three Approaches NegEx, PyConTextNLP and SynNeg.pdf:pdf},
keywords = {clinical text,negation detection,syntactic analysis},
title = {{Negation Scope Delimitation in Clinical Text Using Three Approaches: NegEx, PyConTextNLP and SynNeg}},
year = {2013}
}
@incollection{Tottie1991,
author = {Tottie, Gunnel},
pages = {353},
publisher = {Academic Press},
title = {{Negation in English speech and writing : a study in variation}},
year = {1991}
}
@inproceedings{turney2002thumbs,
author = {Turney, Peter D},
booktitle = {Proceedings of the 40th annual meeting on association for computational linguistics},
file = {::},
organization = {Association for Computational Linguistics},
pages = {417--424},
title = {{Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews}},
year = {2002}
}
@article{Viera2005,
author = {Viera, Anthony J and Garrett, Joanne M},
file = {::},
number = {May},
pages = {360--363},
title = {{Understanding Interobserver Agreement : The Kappa Statistic}},
year = {2005}
}
@phdthesis{Vo2015,
author = {Vo, Dinh and Tran, Minh},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vo, Tran - 2015 - Dự đo{\'{a}}n sự ph{\'{a}}t triển của bệnh ung thư phổi dựa tr{\^{e}}n bệnh {\'{a}}n điện tử.pdf:pdf},
title = {{Dự đo{\'{a}}n sự ph{\'{a}}t triển của bệnh ung thư phổi dựa tr{\^{e}}n bệnh {\'{a}}n điện tử}},
year = {2015}
}
@article{Ware2009,
author = {Ware, Mark and Consulting, Mark Ware and Mabe, Michael},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ware, Consulting, Mabe - 2009 - The stm report An overview of scientific and scholarly journal publishing.pdf:pdf},
title = {{The stm report An overview of scientific and scholarly journal publishing}},
year = {2009}
}
@article{whitelaw2005using,
author = {Whitelaw, Casey and Garg, Navendu and Argamon, Shlomo},
file = {::},
journal = {Proceedings of the 14th Association for Computing Machinery International Conference on Information and Knowledge Management},
pages = {625--631},
title = {{Using appraisal groups for sentiment analysis}},
year = {2005}
}
@inproceedings{wiegand2010survey,
author = {Wiegand, Michael and Balahur, Alexandra and Roth, Benjamin and Klakow, Dietrich and Montoyo, Andr{\'{e}}s},
booktitle = {Proceedings of the workshop on negation and speculation in natural language processing},
file = {::},
organization = {Association for Computational Linguistics},
pages = {60--68},
title = {{A survey on the role of negation in sentiment analysis}},
year = {2010}
}
@inproceedings{wilson2005recognizing,
author = {Wilson, Theresa and Wiebe, Janyce and Hoffmann, Paul},
booktitle = {Proceedings of the conference on human language technology and empirical methods in natural language processing},
file = {::},
organization = {Association for Computational Linguistics},
pages = {347--354},
title = {{Recognizing contextual polarity in phrase-level sentiment analysis}},
year = {2005}
}
@article{xia09improving,
author = {Xia, Lei and Gentile, Anna Lisa and Munro, James},
file = {::},
journal = {Proceedings of the 12th International Conference on Text, Speech and Dialogue},
pages = {70--76},
title = {{Improving Patient OpinionMining through Multi-step Classification}},
year = {2009}
}
@article{xu2012suicide,
author = {Xu, Yan and Wang, Yue and Liu, Jiahua and Tu, Zhuowen and Sun, Jian-Tao and Tsujii, Junichi and Chang, Eric},
file = {::},
journal = {Biomedical Informatics Insights},
pages = {31--41},
title = {{Suicide note sentiment classification: a supervised approach augmented by web data}},
volume = {5},
year = {2012}
}
@article{Yu2003,
abstract = {We identify a new task in the ongoing analysis of opinions: finding propositional opinions, sentential complements which for many verbs contain the actual opinion, rather than full opinion sentences. We propose an extension of semantic parsing techniques, coupled with additional lexical and syntactic features, that can produce labels for propositional opinions as opposed to other syntactic constituents. We describe the annotation of a small corpus of 5,139 sentences with propositional opinion information, and use this corpus to evaluate our methods. We also present results that indicate that the proposed methods can be extended to the related task of identifying opinion holders and associating them with propositional opinions.},
author = {Yu, Hong and Hatzivassiloglou, Vasileios},
file = {::},
journal = {Proceedings of the 2003 conference on Empirical methods in natural language processing -},
keywords = {Empirical methods in natural language processing},
number = {3},
pages = {129--136},
title = {{Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences}},
year = {2003}
}
@article{Zeng2007,
abstract = {Negation status identification for findings ordiagnoses is an important medical data miningproblem. Negative qualifier assigned to a medicalcondition may indicate the absence of the condition,so the ability to reliably identify the negation statusof medical concepts affects the quality of resultsproduced by the indexing and search tools.Searching for the best negation algorithm to use inour negation module for the suite of NLP tools, wemodified two existing regular expression-basedalgorithms in an attempt to improve theirperformance, and created two classification-basedmethods. The classification-based algorithms weretrained on 1745 discharge reports from a Boston-based hospital. The algorithms were evaluated on100 randomly-chosen outpatient reports from twodifferent Boston-based hospitals, and the results werecompared to the gold standard created by twoindependent human reviewers.The regular expression and syntactic processing-based algorithms appeared to have better agreement(Kappa = 0.77 to 0.79) with the human reviewersthan the classification-based algorithms (Kappa =0.57 to 0.75). The accuracy of regular expressionsmethods (91.9-92.3{\%}) was also higher than that ofclassification based methods (83.5-89.9{\%}).Based on our results, we have selected NegExalgorithm for our negation module.},
annote = {Technical report, DSG},
author = {Zeng, Qing and Goryachev, Sergey and Sordo, Margherita and Ngo, Long},
file = {:C$\backslash$:/Users/Flynn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goryachev et al. - Unknown - Implementation and Evaluation of Four Different Methods of Negation Detection.pdf:pdf},
keywords = {Academia,Opinion Analysis,PhD Dissertation,References},
pages = {1--6},
title = {{Negation Detection using Regular Expression, Syntactic and Classification Methods}},
year = {2007}
}
@article{Zhang2015,
abstract = {Khan, A. Z., Atique, M., {\&} Thakare, V. M. (2015). Combining lexicon-based and learning-based methods for Twitter sentiment analysis. International Journal of Electronics, Communication and Soft Computing Science {\&} Engineering (IJECSCSE), 89.},
author = {Zhang, L and Ghosh, R and Dekhil, M and Hsu, M and Liu, B},
file = {::},
journal = {International Journal of Electronics, Communication and Soft Computing Science {\&} Engineering (IJECSCSE)},
pages = {1--8},
title = {{Combining lexicon-based and learning-based methods for Twitter sentiment analysis}},
volume = {89},
year = {2015}
}
